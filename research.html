   <!DOCTYPE html>
<html>
  <body>
<div id="research" class="section">
      <h2>Research</h2>

      <h3>Advancing Music Understanding through Multimodal Information Processing</h3>
      <p><strong>Overview:</strong> My research explores how <strong>multimodal information processing</strong> can enhance <strong>music understanding</strong> for both experts and general audiences. Music, as a deeply multimodal experience, combines auditory, visual, and even tactile elements. My work aims to leverage these aspects to improve machine learning models and make music more accessible and comprehensible.</p>

      <h3>Core Research Goals</h3>
      <ul>
        <li><strong>Multimodal Data Integration:</strong> Explore how combining audio, text, and visual data can improve machine understanding of music.</li>
        <li><strong>Explainability in MIR:</strong> Develop systems that are not only accurate but also interpretable and inclusive.</li>
        <li><strong>Sensory Engagement:</strong> Investigate how engaging multiple senses can enhance audience understanding of musical contexts.</li>
      </ul>

      <h3>Selected Publications</h3>
      <ol>
        <li>Christodoulou, A.-M. et al., "Multimodal Approaches in Music Information Retrieval," <em>Journal of Music Technology Research</em>, 2024.</li>
        <li>Christodoulou, A.-M., "Exploring Multimodal Music Understanding for Non-Experts," <em>Proceedings of the ISMIR Conference</em>, 2023.</li>
        <li>Christodoulou, A.-M., "Deep Learning Applications for Multimodal Music Analysis," <em>ACM Transactions on Audio Processing</em>, 2023.</li>
      </ol>

      <p>For more details on my research, visit my <a href="https://scholar.google.com/">Google Scholar Profile</a> or <a href="https://www.uio.no/ritmo/">RITMO, University of Oslo</a>.</p>
    </div>
  </div>
     </html>

<nav>
  <a href="index.html">Home</a>
  <a href="about.html">About</a>
</nav>

