   <!DOCTYPE html>
<html>

   <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Anna-Maria Christodoulou - Combining Music with High-Tech</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <style>
    body {
      font-family: 'Arial', sans-serif;
      background-color: #9ee0f0;
      margin: 0;
      padding: 0;
      text-align: center;
    }

    header {
      text-align: center;
      padding: 20px;
      background-color: #005c7a;
      color: #fff;
    }

    header img {
      border-radius: 50%;
    }

    nav {
      background-color: #003d50;
      overflow: hidden;
    }

    nav a {
      float: none;
      display: inline-block;
      color: white;
      text-align: center;
      padding: 14px 16px;
      text-decoration: none;
    }

    nav a:hover {
      background-color: #ddd;
      color: black;
    }

    .main-content {
      margin: 20px;
      text-align: center;
    }

    p {
      line-height: 1.6;
      color: #333;
    }

    .contact-icons {
      margin-top: 20px;
    }

    .contact-icons a {
      margin: 0 10px;
      color: #005c7a;
      font-size: 2rem;
      text-decoration: none;
    }

    .contact-icons a:hover {
      color: #003d50;
    }
  </style>
</head>

  <nav>
    <a href="index.html">Home</a>
    <a href="about.html">About</a>
  </nav>
   
  <body>
<div id="research" class="section">
      <h2>Research</h2>

      <h3>Advancing Music Understanding through Multimodal Information Processing</h3>
      <p><strong>Overview:</strong> My PhD research project explores the role of multimodal information in music understanding. Drawing inspiration from the inherent multimodality of music itself, the project seeks to enhance the contextual comprehension of music for non-experts by integrating insights from musicology, music psychology, and music technology. The core of the project lies in exploring how the deliberate integration of complementary information sources, tailored to specific tasks, can deepen our understanding of music. This includes investigating the effectiveness of machine learning models in analyzing multimodal music data, as well as the impact of engaging multiple sensory modalities (auditory, visual, tactile) on audience comprehension of musical contexts. By bridging the gap between scientific analysis and experiential understanding, this research aims to contribute to a more inclusive and accessible experience of music.

      <h3>Selected Publications</h3>
      <ul>
        <li>Christodoulou, AM., Lartillot, O. & Jensenius, A.R. Multimodal music datasets? Challenges and future goals in music processing. Int J Multimed Info Retr 13, 37 (2024). https://doi.org/10.1007/s13735-024-00344-6</li>
        <li>Christodoulou, A.-M., & Jensenius, A. R. (2024). Navigating Challenges in Multimodal Music Data Management for AI Systems. AIMC 2024 (09/09 - 11/09 ). Retrieved from https://aimc2024.pubpub.org/pub/4y99xcm3</li>
      </ul>

      <p>For more details on my research, visit my <a href="https://scholar.google.com/citations?user=GNsx1Z4AAAAJ&hl=en&authuser=1">Google Scholar Profile</a> or <a href="https://www.uio.no/ritmo/english/people/phd-fellows/annammc/index.html">RITMO, University of Oslo</a>.</p>
    </div>
  </div>
     </html>

