   <!DOCTYPE html>
<html>

   <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Anna-Maria Christodoulou - Combining Music with High-Tech</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <style>
    body {
      font-family: 'Arial', sans-serif;
      background-color: #9ee0f0;
      margin: 0;
      padding: 0;
      text-align: center;
    }

    header {
      text-align: center;
      padding: 20px;
      background-color: #005c7a;
      color: #fff;
    }

    header img {
      border-radius: 50%;
    }

    nav {
      background-color: #003d50;
      overflow: hidden;
    }

    nav a {
      float: none;
      display: inline-block;
      color: white;
      text-align: center;
      padding: 14px 16px;
      text-decoration: none;
    }

    nav a:hover {
      background-color: #ddd;
      color: black;
    }

    .main-content {
      margin: 20px;
      text-align: center;
    }

    p {
      line-height: 1.6;
      color: #333;
    }

    .contact-icons {
      margin-top: 20px;
    }

    .contact-icons a {
      margin: 0 10px;
      color: #005c7a;
      font-size: 2rem;
      text-decoration: none;
    }

    .contact-icons a:hover {
      color: #003d50;
    }
  </style>
</head>

  <nav>
    <a href="index.html">Home</a>
    <a href="about.html">About</a>
  </nav>
   
  <body>
<div id="research" class="section">
      <h2>Research</h2>

      <h3>Advancing Music Understanding through Multimodal Information Processing</h3>
      <p><strong>Overview:</strong> My research explores how <strong>multimodal information processing</strong> can enhance <strong>music understanding</strong> for both experts and general audiences. Music, as a deeply multimodal experience, combines auditory, visual, and even tactile elements. My work aims to leverage these aspects to improve machine learning models and make music more accessible and comprehensible.</p>

      <h3>Core Research Goals</h3>
      <ul>
        <li><strong>Multimodal Data Integration:</strong> Explore how combining audio, text, and visual data can improve machine understanding of music.</li>
        <li><strong>Explainability in MIR:</strong> Develop systems that are not only accurate but also interpretable and inclusive.</li>
        <li><strong>Sensory Engagement:</strong> Investigate how engaging multiple senses can enhance audience understanding of musical contexts.</li>
      </ul>

      <h3>Selected Publications</h3>
      <ol>
        <li>Christodoulou, A.-M. et al., "Multimodal Approaches in Music Information Retrieval," <em>Journal of Music Technology Research</em>, 2024.</li>
        <li>Christodoulou, A.-M., "Exploring Multimodal Music Understanding for Non-Experts," <em>Proceedings of the ISMIR Conference</em>, 2023.</li>
        <li>Christodoulou, A.-M., "Deep Learning Applications for Multimodal Music Analysis," <em>ACM Transactions on Audio Processing</em>, 2023.</li>
      </ol>

      <p>For more details on my research, visit my <a href="https://scholar.google.com/">Google Scholar Profile</a> or <a href="https://www.uio.no/ritmo/">RITMO, University of Oslo</a>.</p>
    </div>
  </div>
     </html>

