<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Research Questions ‚Äì Anna-Maria Christodoulou</title>

  <!-- Thebe for interactive Python cells -->
<script src="https://unpkg.com/thebe@latest/lib/index.js"></script>
<link rel="stylesheet" href="https://unpkg.com/thebe@latest/lib/thebe.css" />

  <style>
    body {
      font-family: "Trebuchet MS", sans-serif;
      background-color: #9ee0f0;
      margin: 0;
      padding: 0;
    }
    header {
      text-align: center;
      padding: 25px;
      background-color: #005c7a;
      color: #fff;
    }
    nav {
      background-color: #003d50;
      text-align: center;
      padding: 12px 0;
    }
    nav a {
      color: white;
      margin: 0 15px;
      text-decoration: none;
      font-size: 1.1rem;
      font-weight: bold;
    }
    nav a:hover {
      text-decoration: underline;
    }
    .container {
      max-width: 900px;
      margin: 30px auto;
      background: #ffffffdd;
      padding: 25px;
      border-radius: 12px;
    }
    h2 {
      color: #003d50;
    }
    p {
      line-height: 1.6;
    }

    /* --- PLAYFUL RESEARCH MAP --- */
    .map-container {
      margin-top: 35px;
      padding: 20px;
      background: #e7faff;
      border-radius: 12px;
      border: 2px dashed #00789e;
    }
    .map-title {
      text-align: center;
      font-size: 1.4rem;
      margin-bottom: 15px;
      color: #005c7a;
      font-weight: bold;
    }
    .map {
      display: flex;
      flex-direction: column;
      gap: 20px;
    }
    .map-row {
      display: flex;
      justify-content: center;
      gap: 20px;
      flex-wrap: wrap;
    }
    .bubble {
      background: #fff;
      border-radius: 20px;
      padding: 15px 20px;
      min-width: 180px;
      text-align: center;
      border: 3px solid #00a4c8;
      font-weight: bold;
      transition: transform 0.2s;
    }
    .bubble:hover {
      transform: scale(1.06);
      background: #dafeff;
    }
    .arrow {
      text-align: center;
      font-size: 2rem;
      color: #005c7a;
    }

    /* INTERACTIVE DESCRIPTION BOX */
#info-box {
display: none;
margin-top: 20px;
padding: 15px;
border-radius: 10px;
background: #ffffffcc;
border: 2px solid #00789e;
}


/* INTERACTIVE CODE BLOCKS */
.cell-block {
background: #f4f4f4;
padding: 15px;
margin: 20px 0;
border-radius: 8px;
border: 1px solid #cccccc;
}

  </style>
</head>

<body>
  <header>
    <h1>Research Questions</h1>
    <p>An introduction to my PhD project</p>
  </header>

  <nav>
    <a href="index.html">Home</a>
    <a href="about.html">About</a>
    <a href="research.html">Research</a>
  </nav>

  <div class="container">

    <h2>What My PhD Is About</h2>
    <p>
      My PhD examines how computers can better understand music by looking at
      more than just audio. I do that by looking at how we humans understand music by not only
      listening to it but also moving to the beat, looking at different visuals, reading text/lyrics,
      understanding cultural cues, and monitoring the physical behavior of performers. This multidimensional 
      integration is called <strong>multimodal perception</strong>. When we combine recordings of multiple data
      sources in a computational system, we call it <strong>multimodal fusion</strong>, and it is a way to model music in a
      deeper and more human-like manner
    </p>

    <p>
      This page explains the main research questions in my project,
      and gives you a visual ‚Äúmap‚Äù of how the ideas connect.
    </p>

    <!-- PLAYFUL GRAPHICAL MAP -->
    <div class="map-container">
      <div class="map-title">Multimodal Music Research Map</div>
      <div class="map">

        <div class="map-row">
          <div class="bubble">Music is Multimodal</div>
          <div class="bubble">We Use Data to Study Music</div>
          <div class="bubble">Technology Supports Understanding</div>
        </div>

        <div class="arrow">‚¨áÔ∏è</div>

        <div class="map-row">
          <div class="bubble">RQ1: What Is multimodality in music processing?</div>
          <div class="bubble">RQ2: To which extent can technology enhance the contextual understanding of music?</div>
        </div>

        <div class="arrow">‚¨áÔ∏è</div>

        <div class="map-row">
          <div class="bubble">Definitions & Frameworks</div>
          <div class="bubble">Audio-Video-Motion Datasets</div>
          <div class="bubble">Music Question Answering</div>
          <div class="bubble">Ethics & Data Management</div>
        </div>

        <div class="arrow">‚¨áÔ∏è</div>

        <div class="map-row">
          <div class="bubble" style="background:#c8ffe0;">Better Understanding of Music</div>
        </div>

      </div>
    </div>

    <h2>Research Question 1</h2>
    <p>
      <strong>How can multimodality be defined and used in computational music analysis?</strong>
    </p>
    <p>
      Different fields talk about multimodality in different ways. In my PhD,
      I propose a simple idea:
      <em>use multiple data sources only when each one adds something new and meaningful to the task.</em>
      This helps researchers choose the right combination of audio, video,
      motion, text, and metadata, depending on what they want to understand.
    </p>

    <h2>Research Question 2</h2>
    <p>
      <strong>How much can technology enhance the contextual understanding of music?</strong>
    </p>
    <p>
      I worked with several multimodal datasets, such as folk music, classical music,
      ensemble performance, motion capture, lyrics, and metadata, to see
      whether machines can answer questions like:
    </p>
    <ul>
      <li>What is happening in the performance?</li>
      <li>Why is the performer moving this way?</li>
      <li>How does the audience react at certain points during the performance?</li>
    </ul>

    <p>
      Before we dive into some details, perhaps you would like to know:

      <p>
        <strong>What is Music Performance?</strong>
      </p>
      <p>Let's just say that music performance is music in action. It‚Äôs when performers turn compositions, improvisations, or musical ideas into sound, movement, and 
        expression for an audience. Think of it as storytelling with sound, gestures, and emotion.</p>
      <p>
        <strong>What is Music Performance Context?</strong>
      </p>
    <p>Context is everything around the music that shapes its meaning: the venue, the audience, the gestures of performers, cultural rules, and even the placement of 
      instruments. It‚Äôs what makes the same piece of music feel different in a concert hall, a jazz club, or a folk festival.</p>
      <p><strong>What is Music Understanding?</strong></p>
    <p>Music understanding begins when we stop simply hearing sound around us and start listening with attention. 
      Hearing is passive and happens automatically. Listening is active and happens when we focus, follow, feel, and make sense of what unfolds in the music. 
      Understanding music isn‚Äôt about knowing fancy terminology or analyzing scores, but about noticing what the music is doing, how it moves, how it feels, and how our
      own experiences help us interpret it.</p>
    <p>People often imagine that only trained musicians or musicologists can ‚Äúunderstand‚Äù music, but everyone can! A person may not know what a motif or cadence is, 
      but they can still feel repetition, arrival, contrast, or surprise. They can follow a musical idea as it evolves, or sense the energy in a performer‚Äôs gesture. 
      Understanding music is less about naming things and more about experiencing how music flows and how it speaks.
</p>
<div class="tree">
  <ul>
    <li>
      <strong>Music Understanding</strong>
      <ul>
        <li>
          <strong>Listening (not just hearing!)</strong>
          <ul>
            <li>Attention + curiosity</li>
          </ul>
        </li>
        <li>
          <strong>Perception</strong>
          <ul>
            <li>How we group, follow, and sense musical ideas</li>
          </ul>
        </li>
        <li>
          <strong>Cognition</strong>
          <ul>
            <li>Memory, prediction, timing, reasoning</li>
          </ul>
        </li>
        <li>
          <strong>Embodiment</strong>
          <ul>
            <li>How our body feels, moves, and simulates the music</li>
          </ul>
        </li>
        <li>
          <strong>Emotion &amp; Experience</strong>
          <ul>
            <li>What the music makes us feel and imagine</li>
          </ul>
        </li>
        <li>
          <strong>Culture</strong>
          <ul>
            <li>What our background teaches us to notice and value</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</div>

<style>
/* simple tree lines */
.tree ul {
  padding-left: 1.2rem;
  position: relative;
  list-style: none;
  margin: 0;
}
.tree ul::before {
  content: "";
  position: absolute;
  top: 0;
  left: 0.55rem;            /* adjust to align vertical line */
  bottom: 0;
  width: 1px;
  background: #cfdbe0;      /* vertical connector color */
}
.tree li {
  margin: 0.5rem 0;
  padding-left: 1rem;
  position: relative;
}
.tree li::before {
  content: "";
  position: absolute;
  left: 0;
  top: 0.9rem;              /* position horizontal connector */
  width: 0.6rem;
  height: 1px;
  background: #cfdbe0;
}
.tree strong { color: #003d50; }
.tree li ul::before { left: 0.35rem; } /* nested alignment */
</style>
    <p><strong>What is music information processing?</strong></p>
    <p>Computational music information processing is about turning the physical experience of music into digital data, and then into forms of machine cognition, so that
      computers can help us explore, analyze, and understand music in new ways.</p>

    <div class="cell-block thebe-cell" data-executable="true" data-language="python">
<pre data-executable="true" data-language="python">
metadata = {
"tempo": 95,
"key": "A minor",
"instrumentation": ["violin", "laouto", "voice"],
}


question = "What is the key of the piece?"


if "key" in question.lower():
answer = metadata["key"]
else:
answer = "Not sure yet!"


answer
</pre>
</div>


</div>


<script>
function showInfo(text) {
const box = document.getElementById("info-box");
box.innerHTML = text;
box.style.display = "block";
}


thebe.config = {
useBinder: true,
binderOptions: {
repo: "binder-examples/jupyter-stacks-datascience",
ref: "master",
}
};
thebe.bootstrap();
</script>

  <!-- MULTIMODALITY TEST -->
<div class="test-container">
  <h2>üß™ Is My Dataset Multimodal?</h2>
  <p>Answer two quick questions to find out.</p>

  <!-- Question 1 -->
  <div class="test-block">
    <h3>1) What type of task are you performing?</h3>

    <div class="accordion">

      <!-- 3.1 Categorization -->
      <div class="acc-item">
        <button class="acc-btn">3.1 Categorization-Oriented</button>
        <div class="acc-content">
          <div class="task-option" data-task="Emotion / Affect Recognition">Emotion / Affect Recognition</div>
          <div class="task-option" data-task="Genre Classification">Genre Classification</div>
          <div class="task-option" data-task="Auto-Tagging">Auto-Tagging</div>
          <div class="task-option" data-task="Musical Gesture Classification">Musical Gesture Classification</div>
          <div class="task-option" data-task="Singing Voice Analysis">Singing Voice Analysis</div>
        </div>
      </div>

      <!-- 3.2 Time-dependent -->
      <div class="acc-item">
        <button class="acc-btn">3.2 Time-Dependent Representation-Oriented</button>
        <div class="acc-content">
          <div class="task-option" data-task="Source Separation">Source Separation</div>
          <div class="task-option" data-task="Piano Tutoring">Piano Tutoring</div>
          <div class="task-option" data-task="Music Segmentation">Music Segmentation</div>
          <div class="task-option" data-task="Music Structure Analysis">Music Structure Analysis</div>
          <div class="task-option" data-task="Music Transcription">Music Transcription</div>
          <div class="task-option" data-task="Instrument Performance Analysis">Instrument Performance Analysis</div>
        </div>
      </div>

      <!-- 3.3 Similarity -->
      <div class="acc-item">
        <button class="acc-btn">3.3 Music Similarity-Oriented</button>
        <div class="acc-content">
          <div class="task-option" data-task="Song Retrieval">Song Retrieval</div>
          <div class="task-option" data-task="Music Exploration & Discovery">Music Exploration & Discovery</div>
        </div>
      </div>

      <!-- 3.4 Generation -->
      <div class="acc-item">
        <button class="acc-btn">3.4 Music Generation</button>
        <div class="acc-content">
          <div class="task-option" data-task="Music Generation">Music Generation</div>
        </div>
      </div>

      <!-- 3.5 Multi-Task -->
      <div class="acc-item">
        <button class="acc-btn">3.5 Multi-Task Datasets</button>
        <div class="acc-content">
          <div class="task-option" data-task="Multi-Task / Foundational Models">Multi-Task / Foundational Models</div>
          <div class="task-option" data-task="Music Captioning">Music Captioning</div>
          <div class="task-option" data-task="Music-Language Retrieval">Music-Language Retrieval</div>
        </div>
      </div>

    </div>

    <!-- Selected task display -->
    <p id="selectedTask" class="selected-display">Selected task: <em>none yet</em></p>
  </div>

  <!-- Question 2 -->
  <div class="test-block">
    <h3>2) What kinds of data exist in your dataset?</h3>
    <p>Select all that apply:</p>

    <div class="data-options">
      <button class="data-btn" data-type="Audio">Audio</button>
      <button class="data-btn" data-type="Video">Video</button>
      <button class="data-btn" data-type="Motion">Motion / MoCap</button>
      <button class="data-btn" data-type="Text">Text / Lyrics</button>
      <button class="data-btn" data-type="Score">Score / Notation</button>
      <button class="data-btn" data-type="MIDI">MIDI</button>
      <button class="data-btn" data-type="Metadata">Metadata</button>
      <button class="data-btn" data-type="Image">Images</button>
      <button class="data-btn" data-type="Sensor">Physiological Data (EMG/ECG/IMU)</button>
      <button class="data-btn" data-type="Other">Other</button>
    </div>
  </div>

  <!-- Button -->
  <div class="center">
    <button id="evaluateBtn" class="evaluate-btn">Evaluate</button>
  </div>

  <!-- Result -->
  <div id="resultBox" class="result-box hidden"></div>
</div>

<style>
/* -- SAME styles as before, with additions -- */

.test-container {
  margin-top: 40px;
  padding: 20px;
  background: #e7faff;
  border-radius: 12px;
  border: 2px dashed #00789e;
}

.test-block { margin-bottom: 25px; }

/* Accordion */
.accordion { width: 100%; }

.acc-btn {
  width: 100%;
  background: #005c7a;
  color: white;
  padding: 12px;
  border: none;
  border-radius: 8px;
  font-size: 1rem;
  text-align: left;
  cursor: pointer;
  margin-bottom: 5px;
}

.acc-btn:hover {
  background: #00789e;
}

.acc-content {
  display: none;
  padding: 10px;
  background: #ffffff;
  border-left: 3px solid #00789e;
  border-radius: 5px;
  margin-bottom: 10px;
}

.task-option {
  padding: 8px;
  cursor: pointer;
  border-radius: 6px;
  margin: 4px 0;
  transition: 0.2s;
}

.task-option:hover { background: #dafeff; }

.task-option.selected {
  background: #00a4c8;
  color: white;
}

.selected-display {
  margin-top: 10px;
  font-style: italic;
}

/* Data buttons (unchanged) */
.data-options { display: flex; flex-wrap: wrap; gap: 10px; }
.data-btn {
  padding: 8px 14px;
  border: 2px solid #00a4c8;
  border-radius: 20px;
  background: #fff;
  cursor: pointer;
  transition: 0.2s;
  font-weight: bold;
}
.data-btn:hover { background: #dafeff; transform: scale(1.05); }
.data-btn.selected { background: #00a4c8; color: white; transform: scale(1.05); }

/* Evaluate button */
.evaluate-btn {
  padding: 12px 20px;
  background: #005c7a;
  color: white;
  font-size: 1.1rem;
  border: none;
  border-radius: 12px;
  cursor: pointer;
}
.evaluate-btn:hover { background: #00789e; }

.result-box {
  margin-top: 25px;
  padding: 18px;
  border-radius: 10px;
  font-size: 1.2rem;
  font-weight: bold;
  text-align: center;
}
.hidden { display: none; }

.center { text-align: center; }
</style>

<script>
// Accordion logic
document.querySelectorAll(".acc-btn").forEach(btn => {
  btn.addEventListener("click", () => {
    const content = btn.nextElementSibling;
    content.style.display = content.style.display === "block" ? "none" : "block";
  });
});

// Task selection logic
let currentTask = "";
document.querySelectorAll(".task-option").forEach(opt => {
  opt.addEventListener("click", () => {
    document.querySelectorAll(".task-option").forEach(o => o.classList.remove("selected"));
    opt.classList.add("selected");
    currentTask = opt.dataset.task;
    document.getElementById("selectedTask").innerHTML =
      "Selected task: <strong>" + currentTask + "</strong>";
  });
});

// Data selection
document.querySelectorAll(".data-btn").forEach(btn => {
  btn.addEventListener("click", () => {
    btn.classList.toggle("selected");
  });
});

// Evaluation
document.getElementById("evaluateBtn").addEventListener("click", () => {
  const selectedData = [...document.querySelectorAll(".data-btn.selected")];
  const resultBox = document.getElementById("resultBox");
  resultBox.classList.remove("hidden");

  if (!currentTask) {
    resultBox.style.background = "#fff3cd";
    resultBox.style.color = "#856404";
    resultBox.textContent = "Please select a task first!";
    return;
  }

  if (selectedData.length === 0) {
    resultBox.style.background = "#fff3cd";
    resultBox.style.color = "#856404";
    resultBox.textContent = "Please select at least one data type.";
    return;
  }

  if (selectedData.length > 1) {
    resultBox.style.background = "#d4f8e8";
    resultBox.style.color = "#06623b";
    resultBox.innerHTML =
      "‚úÖ YES ‚Äî your dataset is multimodal, as you deliberately integrate varied information sources tailored to your task.!<br><small>You are using <strong>" +
      selectedData.length +
      "</strong> modalities.</small>";
  } else {
    resultBox.style.background = "#ffe0e0";
    resultBox.style.color = "#8a1f1f";
    resultBox.textContent = "‚ùå No ‚Äî your dataset uses only one modality.";
  }
});
</script>

</body>
</html>
    

